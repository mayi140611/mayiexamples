{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert4keras\n",
    "by 苏剑林\n",
    "\n",
    "https://github.com/bojone/bert4keras\n",
    "\n",
    "https://bert4keras.spaces.ac.cn/\n",
    "\n",
    "## 功能\n",
    "\n",
    "    加载bert/roberta/albert的预训练权重进行finetune；\n",
    "    实现语言模型、seq2seq所需要的attention mask；\n",
    "    丰富的examples；https://github.com/bojone/bert4keras/tree/master/examples\n",
    "    从零预训练代码（支持TPU、多GPU，请看pretraining）；\n",
    "    兼容keras、tf.keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装\n",
    "安装稳定版：\n",
    "\n",
    "pip install bert4keras\n",
    "\n",
    "安装最新版：\n",
    "\n",
    "pip install git+https://www.github.com/bojone/bert4keras.git\n",
    "## 权重\n",
    "\n",
    "目前支持加载的权重：\n",
    "\n",
    "    Google原版bert: https://github.com/google-research/bert\n",
    "    brightmart版roberta: https://github.com/brightmart/roberta_zh\n",
    "    哈工大版roberta: https://github.com/ymcui/Chinese-BERT-wwm\n",
    "    Google原版albert[例子]: https://github.com/google-research/ALBERT\n",
    "    brightmart版albert: https://github.com/brightmart/albert_zh\n",
    "    转换后的albert: https://github.com/bojone/albert_zh\n",
    "    华为的NEZHA: https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA\n",
    "    自研语言模型: https://github.com/ZhuiyiTechnology/pretrained-models\n",
    "    T5模型: https://github.com/google-research/text-to-text-transfer-transformer\n",
    "    GPT2_ML: https://github.com/imcaspar/gpt2-ml\n",
    "    Google原版ELECTRA: https://github.com/google-research/electra\n",
    "    哈工大版ELECTRA: https://github.com/ymcui/Chinese-ELECTRA\n",
    "    CLUE版ELECTRA: https://github.com/CLUEbenchmark/ELECTRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert4keras==0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://www.github.com/bojone/bert4keras.git\n",
    "!pip freeze | grep keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#! -*- coding: utf-8 -*-\n",
    "# 测试代码可用性\n",
    "\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras==2.3.1\r\n",
      "Keras-Applications==1.0.8\r\n",
      "Keras-Preprocessing==1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.1.0\r\n",
      "tensorflow-datasets==1.3.0\r\n",
      "tensorflow-estimator==2.1.0\r\n",
      "tensorflow-metadata==0.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dir = '/Users/luoyonggui/Documents/nlpdata/chinese_L-12_H-768_A-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = f'{bert_dir}/bert_config.json'\n",
    "checkpoint_path = f'{bert_dir}/bert_model.ckpt'\n",
    "dict_path = f'{bert_dir}/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用bert base模型来编码句子的简单例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码分为两部分：\n",
    "* 第一部分是tokenizer的建立，bert4keras.tokenizers里边包含了对原版BERT的tokenizer的完整复现，同时还补充了一下常用的功能；\n",
    "* 第二部分就是BERT模型的建立，其主要函数是build_transformer_model，其定义如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_model(\n",
    "    config_path=None,  # 模型的配置文件（对应的文件为json格式）\n",
    "    checkpoint_path=None,  # 模型的预训练权重（tensorflow的ckpt格式）\n",
    "    model='bert',  # 模型的类型（bert、albert、albert_unshared、nezha、electra、gpt2_ml、t5）\n",
    "    application='encoder',  # 模型的用途（encoder、lm、unilm）\n",
    "    return_keras_model=True,  # 返回Keras模型，还是返回bert4keras的模型类\n",
    "    **kwargs  # 其他传递参数\n",
    "):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build_transformer_model各参数的含义很难用几句话表达清楚，不过在这个10分钟教程里，这些细节并不是特别重要，所以暂时略去。学习一个框架最好的方法还是多看例子，所以还是恳请用户多参考github上提供的examples https://github.com/bojone/bert4keras/tree/master/examples。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(dict_path) # 建立分词器\n",
    "# 编码测试\n",
    "token_ids, segment_ids = tokenizer.encode('语言模型')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 6427, 6241, 3563, 1798, 102], [0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids, segment_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，编码以后是2个list， list长度为编码句子的长度+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 6427, 6241, 102], [0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以限制句子的长度\n",
    "tokenizer.encode('语言模型', max_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 6427, 6241, 3563, 1798, 102], [0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以限制句子的长度\n",
    "tokenizer.encode('语言模型', max_length=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型，加载权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 返回keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_transformer_model(config_path, checkpoint_path, \n",
    "                               return_keras_model=True) # 建立模型，加载权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Input-Token_4:0' shape=(None, None) dtype=float32>,\n",
       " <tf.Tensor 'Input-Segment_4:0' shape=(None, None) dtype=float32>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取bert的输入层\n",
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Transformer-11-FeedForward-Norm_1/add_1:0' shape=(None, None, 768) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取bert的输出层\n",
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert的层list\n",
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x13db727f0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x13db727b8>,\n",
       " <bert4keras.layers.Embedding at 0x13db72710>,\n",
       " <bert4keras.layers.Embedding at 0x13db726d8>,\n",
       " <keras.layers.merge.Add at 0x13db723c8>,\n",
       " <bert4keras.layers.PositionEmbedding at 0x13db725c0>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13db72630>,\n",
       " <keras.layers.core.Dropout at 0x13db72550>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x13da8d8d0>,\n",
       " <keras.layers.core.Dropout at 0x1422f12e8>,\n",
       " <keras.layers.merge.Add at 0x1422f1358>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13dac6f98>,\n",
       " <bert4keras.layers.FeedForward at 0x13dabfc18>,\n",
       " <keras.layers.core.Dropout at 0x13dd59f98>,\n",
       " <keras.layers.merge.Add at 0x13dab0e80>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1469980b8>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x1469986a0>,\n",
       " <keras.layers.core.Dropout at 0x146998198>,\n",
       " <keras.layers.merge.Add at 0x13dd40358>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13dd402e8>,\n",
       " <bert4keras.layers.FeedForward at 0x13dd30a90>,\n",
       " <keras.layers.core.Dropout at 0x13db6e1d0>,\n",
       " <keras.layers.merge.Add at 0x13db6e198>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13db2edd8>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x13db16940>,\n",
       " <keras.layers.core.Dropout at 0x13db03710>,\n",
       " <keras.layers.merge.Add at 0x13db034a8>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13db036a0>,\n",
       " <bert4keras.layers.FeedForward at 0x13daf14a8>,\n",
       " <keras.layers.core.Dropout at 0x13dcba208>,\n",
       " <keras.layers.merge.Add at 0x13dcc8a90>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13dcf32e8>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x13dd2a358>,\n",
       " <keras.layers.core.Dropout at 0x13dcd8860>,\n",
       " <keras.layers.merge.Add at 0x13dcd85f8>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13dcd87f0>,\n",
       " <bert4keras.layers.FeedForward at 0x13dce8588>,\n",
       " <keras.layers.core.Dropout at 0x13dc026a0>,\n",
       " <keras.layers.merge.Add at 0x13dc02438>,\n",
       " <bert4keras.layers.LayerNormalization at 0x13dbbab38>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x13dbbaa90>,\n",
       " <keras.layers.core.Dropout at 0x13dbd3550>,\n",
       " <keras.layers.merge.Add at 0x1469b49b0>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1469b4710>,\n",
       " <bert4keras.layers.FeedForward at 0x1469c5dd8>,\n",
       " <keras.layers.core.Dropout at 0x1469c5e80>,\n",
       " <keras.layers.merge.Add at 0x141e027f0>,\n",
       " <bert4keras.layers.LayerNormalization at 0x141e39668>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x141f69d68>,\n",
       " <keras.layers.core.Dropout at 0x141f79b00>,\n",
       " <keras.layers.merge.Add at 0x141f79898>,\n",
       " <bert4keras.layers.LayerNormalization at 0x141f79860>,\n",
       " <bert4keras.layers.FeedForward at 0x141f79a90>,\n",
       " <keras.layers.core.Dropout at 0x141f89c50>,\n",
       " <keras.layers.merge.Add at 0x141fb6978>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1420a5940>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x1420bdf98>,\n",
       " <keras.layers.core.Dropout at 0x1420ccc50>,\n",
       " <keras.layers.merge.Add at 0x1420cc9b0>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1420f9be0>,\n",
       " <bert4keras.layers.FeedForward at 0x1420deda0>,\n",
       " <keras.layers.core.Dropout at 0x142108ac8>,\n",
       " <keras.layers.merge.Add at 0x142108828>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1466003c8>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x14660a7b8>,\n",
       " <keras.layers.core.Dropout at 0x146626da0>,\n",
       " <keras.layers.merge.Add at 0x146626b00>,\n",
       " <bert4keras.layers.LayerNormalization at 0x146639ef0>,\n",
       " <bert4keras.layers.FeedForward at 0x146639b70>,\n",
       " <keras.layers.core.Dropout at 0x146654e10>,\n",
       " <keras.layers.merge.Add at 0x146667d30>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1466adfd0>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x1467ac908>,\n",
       " <keras.layers.core.Dropout at 0x1467c9c88>,\n",
       " <keras.layers.merge.Add at 0x1467c9ef0>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1467c9c50>,\n",
       " <bert4keras.layers.FeedForward at 0x1467f4e80>,\n",
       " <keras.layers.core.Dropout at 0x14685fbe0>,\n",
       " <keras.layers.merge.Add at 0x146805d68>,\n",
       " <bert4keras.layers.LayerNormalization at 0x14684c240>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x14684c6d8>,\n",
       " <keras.layers.core.Dropout at 0x1468dec50>,\n",
       " <keras.layers.merge.Add at 0x1468c3048>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1468b9da0>,\n",
       " <bert4keras.layers.FeedForward at 0x1468e7cc0>,\n",
       " <keras.layers.core.Dropout at 0x149726f60>,\n",
       " <keras.layers.merge.Add at 0x1468f8c50>,\n",
       " <bert4keras.layers.LayerNormalization at 0x149715320>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x1497152b0>,\n",
       " <keras.layers.core.Dropout at 0x149715828>,\n",
       " <keras.layers.merge.Add at 0x149765fd0>,\n",
       " <bert4keras.layers.LayerNormalization at 0x14973f160>,\n",
       " <bert4keras.layers.FeedForward at 0x149752668>,\n",
       " <keras.layers.core.Dropout at 0x149776da0>,\n",
       " <keras.layers.merge.Add at 0x149776d68>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1497bc080>,\n",
       " <bert4keras.layers.MultiHeadAttention at 0x1497bc978>,\n",
       " <keras.layers.core.Dropout at 0x1497c5c88>,\n",
       " <keras.layers.merge.Add at 0x1497eb2e8>,\n",
       " <bert4keras.layers.LayerNormalization at 0x1497eb278>,\n",
       " <bert4keras.layers.FeedForward at 0x1497fd780>,\n",
       " <keras.layers.core.Dropout at 0x149c84358>,\n",
       " <keras.layers.merge.Add at 0x149c7af60>,\n",
       " <bert4keras.layers.LayerNormalization at 0x149c20f60>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.merge.Add at 0x149c7af60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取bert的倒数第二层\n",
    "model.layers[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 返回keras model的封装类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert4keras.models.BERT"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = build_transformer_model(config_path, checkpoint_path, \n",
    "                               return_keras_model=False) # 建立模型，加载权重\n",
    "type(bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过bert4keras.models.BERT获取keras.engine.training.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Input-Token_5:0' shape=(None, None) dtype=float32>,\n",
       " <tf.Tensor 'Input-Segment_5:0' shape=(None, None) dtype=float32>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取bert的输入层\n",
    "bert.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.initializers.TruncatedNormal at 0x1481d65c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.predict([np.array([token_ids]), np.array([segment_ids])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.63250965,  0.20302312,  0.07936583, ...,  0.49122566,\n",
       "         -0.20493367,  0.25752527],\n",
       "        [-0.7588357 ,  0.09651838,  1.0718755 , ..., -0.61096966,\n",
       "          0.0431218 ,  0.03881414],\n",
       "        [ 0.547703  , -0.79211694,  0.44435284, ...,  0.42449164,\n",
       "          0.41105747,  0.08222783],\n",
       "        [-0.29242492,  0.6052705 ,  0.49968675, ...,  0.86041355,\n",
       "         -0.65331644,  0.5369077 ],\n",
       "        [-0.7473448 ,  0.49431536,  0.7185178 , ...,  0.38486043,\n",
       "         -0.7409052 ,  0.39056796],\n",
       "        [-0.87413776, -0.21650389,  1.3388399 , ...,  0.5816858 ,\n",
       "         -0.4373227 ,  0.56181794]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
